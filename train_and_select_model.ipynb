{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "68c2b945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in /opt/anaconda3/envs/campusx/lib/python3.12/site-packages (3.1.2)\n",
      "Requirement already satisfied: lightgbm in /opt/anaconda3/envs/campusx/lib/python3.12/site-packages (4.6.0)\n",
      "Requirement already satisfied: catboost in /opt/anaconda3/envs/campusx/lib/python3.12/site-packages (1.2.8)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/envs/campusx/lib/python3.12/site-packages (from xgboost) (2.3.4)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/envs/campusx/lib/python3.12/site-packages (from xgboost) (1.16.3)\n",
      "Requirement already satisfied: graphviz in /opt/anaconda3/envs/campusx/lib/python3.12/site-packages (from catboost) (0.21)\n",
      "Requirement already satisfied: matplotlib in /opt/anaconda3/envs/campusx/lib/python3.12/site-packages (from catboost) (3.10.7)\n",
      "Requirement already satisfied: pandas>=0.24 in /opt/anaconda3/envs/campusx/lib/python3.12/site-packages (from catboost) (2.3.3)\n",
      "Requirement already satisfied: plotly in /opt/anaconda3/envs/campusx/lib/python3.12/site-packages (from catboost) (6.5.0)\n",
      "Requirement already satisfied: six in /opt/anaconda3/envs/campusx/lib/python3.12/site-packages (from catboost) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/envs/campusx/lib/python3.12/site-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/envs/campusx/lib/python3.12/site-packages (from pandas>=0.24->catboost) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/envs/campusx/lib/python3.12/site-packages (from pandas>=0.24->catboost) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/envs/campusx/lib/python3.12/site-packages (from matplotlib->catboost) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/envs/campusx/lib/python3.12/site-packages (from matplotlib->catboost) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/envs/campusx/lib/python3.12/site-packages (from matplotlib->catboost) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/anaconda3/envs/campusx/lib/python3.12/site-packages (from matplotlib->catboost) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/envs/campusx/lib/python3.12/site-packages (from matplotlib->catboost) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /opt/anaconda3/envs/campusx/lib/python3.12/site-packages (from matplotlib->catboost) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=3 in /opt/anaconda3/envs/campusx/lib/python3.12/site-packages (from matplotlib->catboost) (3.2.5)\n",
      "Requirement already satisfied: narwhals>=1.15.1 in /opt/anaconda3/envs/campusx/lib/python3.12/site-packages (from plotly->catboost) (2.13.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost lightgbm catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "21a304a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import root_mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "6a71f574",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from xgboost import XGBRegressor\n",
    "    xgb_available = True\n",
    "except Exception:\n",
    "    xgb_available = False\n",
    "\n",
    "try:\n",
    "    from lightgbm import LGBMRegressor\n",
    "    lgb_available = True\n",
    "except Exception:\n",
    "    lgb_available = False\n",
    "\n",
    "try:\n",
    "    from catboost import CatBoostRegressor\n",
    "    cb_available = True\n",
    "except Exception:\n",
    "    cb_available = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "be2fc31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42\n",
    "TEST_SIZE = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "ae4adfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "##UTILITIES\n",
    "# def rmse(y_true, y_pred):\n",
    "#     return root_mean_squared_error(y_true, y_pred, squared=False)\n",
    "\n",
    "def evaluate_predictions_log(y_true_log, y_pred_log):\n",
    "    \"\"\"Return metrics on log scale and on original price scale (expm1).\"\"\"\n",
    "    # Log-target metrics\n",
    "    rmse_log = root_mean_squared_error(y_true_log, y_pred_log)\n",
    "    mae_log = mean_absolute_error(y_true_log, y_pred_log)\n",
    "    r2_log = r2_score(y_true_log, y_pred_log)\n",
    "\n",
    "    # Convert back to price scale\n",
    "    y_true_price = np.expm1(y_true_log)\n",
    "    y_pred_price = np.expm1(y_pred_log)\n",
    "\n",
    "    rmse_price = root_mean_squared_error(y_true_price, y_pred_price)\n",
    "    mae_price = mean_absolute_error(y_true_price, y_pred_price)\n",
    "    r2_price = r2_score(y_true_price, y_pred_price)\n",
    "\n",
    "    return {\n",
    "        \"rmse_log\": rmse_log,\n",
    "        \"mae_log\": mae_log,\n",
    "        \"r2_log\": r2_log,\n",
    "        \"rmse_price\": rmse_price,\n",
    "        \"mae_price\": mae_price,\n",
    "        \"r2_price\": r2_price\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "57634431",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_booster_with_fallback(name, model, X_tr_t, y_tr, X_val_t, y_val):\n",
    "    \"\"\"\n",
    "    Try multiple ways to fit booster with early stopping across library versions:\n",
    "      1) model.fit(..., eval_set=[...], early_stopping_rounds=...)\n",
    "      2) model.fit(..., eval_set=[...], callbacks=[...]) (XGBoost / LightGBM callback)\n",
    "      3) CatBoost: use_best_model=True\n",
    "      4) fallback: model.fit(...) without early stopping\n",
    "    Returns: (fitted_model, method_string)\n",
    "    \"\"\"\n",
    "    default_es = 30\n",
    "    # 1) try classic API\n",
    "    try:\n",
    "        model.fit(X_tr_t, y_tr, eval_set=[(X_val_t, y_val)], early_stopping_rounds=default_es, verbose=False)\n",
    "        return model, \"fit(early_stopping_rounds)\"\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # 2) try callbacks for XGBoost/LightGBM\n",
    "    try:\n",
    "        if \"XGB\" in name and xgb_available:\n",
    "            try:\n",
    "                # attempt xgboost callback import\n",
    "                from xgboost.callback import EarlyStopping\n",
    "                model.fit(X_tr_t, y_tr, eval_set=[(X_val_t, y_val)], callbacks=[EarlyStopping(rounds=default_es)])\n",
    "                return model, \"xgb.callback.EarlyStopping\"\n",
    "            except Exception:\n",
    "                # alternate import path\n",
    "                import xgboost as xgbpkg\n",
    "                try:\n",
    "                    model.fit(X_tr_t, y_tr, eval_set=[(X_val_t, y_val)], callbacks=[xgbpkg.callback.EarlyStopping(rounds=default_es)])\n",
    "                    return model, \"xgbpkg.callback.EarlyStopping\"\n",
    "                except Exception:\n",
    "                    pass\n",
    "\n",
    "        if \"LightGBM\" in name and lgb_available:\n",
    "            try:\n",
    "                from lightgbm import early_stopping\n",
    "                model.fit(X_tr_t, y_tr, eval_set=[(X_val_t, y_val)], callbacks=[early_stopping(default_es)])\n",
    "                return model, \"lightgbm.callback.early_stopping\"\n",
    "            except Exception:\n",
    "                # try package callback\n",
    "                try:\n",
    "                    import lightgbm as lgbpkg\n",
    "                    model.fit(X_tr_t, y_tr, eval_set=[(X_val_t, y_val)], callbacks=[lgbpkg.callback.early_stopping(default_es)])\n",
    "                    return model, \"lgbpkg.callback.early_stopping\"\n",
    "                except Exception:\n",
    "                    pass\n",
    "\n",
    "        if \"CatBoost\" in name and cb_available:\n",
    "            try:\n",
    "                model.fit(X_tr_t, y_tr, eval_set=(X_val_t, y_val), use_best_model=True, verbose=False)\n",
    "                return model, \"catboost.use_best_model\"\n",
    "            except Exception:\n",
    "                pass\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # 3) fallback: fit without early stopping\n",
    "    try:\n",
    "        model.fit(X_tr_t, y_tr)\n",
    "        return model, \"fallback_no_early_stopping\"\n",
    "    except Exception as e:\n",
    "        # If it fails to fit at all, raise\n",
    "        raise RuntimeError(f\"Booster {name} failed to fit in all attempts: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "bb35e3da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (10682, 29)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('processed_flight_data.csv')\n",
    "print(\"Shape:\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "d8b00d75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ---------- Detect whether data is OHE or needs preprocessing ----------\n",
    "# If categorical columns exist as names, we will build a ColumnTransformer.\n",
    "categorical_candidates = [\"Airline\", \"Source\", \"Destination\"]\n",
    "has_categorical = any(c in df.columns for c in categorical_candidates)\n",
    "has_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "b03c1ad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected OHE data or no categorical columns. Skipping ColumnTransformer.\n"
     ]
    }
   ],
   "source": [
    "# If data appears to be OHE already (no categorical columns), we'll skip ColumnTransformer.\n",
    "use_preprocessor = has_categorical\n",
    "\n",
    "if use_preprocessor:\n",
    "    numeric_features = [\"Duration_minutes\", \"stops_num\", \"Dep_Hour\", \"Arrival_Hour\", \"Journey_Day\", \"Journey_Month\"]\n",
    "    cat_features = [c for c in categorical_candidates if c in df.columns]\n",
    "    print(\"Using ColumnTransformer with numeric:\", numeric_features, \"and categorical:\", cat_features)\n",
    "\n",
    "    numeric_transformer = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler())\n",
    "    ])\n",
    "    categorical_transformer = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"missing\")),\n",
    "        (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", sparse=False))\n",
    "    ])\n",
    "    preprocessor = ColumnTransformer([\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, cat_features)\n",
    "    ], remainder=\"drop\")\n",
    "    # Feature names after transform will be built where needed.\n",
    "else:\n",
    "    print(\"Detected OHE data or no categorical columns. Skipping ColumnTransformer.\")\n",
    "    preprocessor = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "817b8c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Prepare X and Y\n",
    "X_all = df.drop(columns=[\"Price\", \"Price_capped\", \"log_Price\"], errors=\"ignore\")\n",
    "y_all = df[\"log_Price\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "33c1ad1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (7477, 26) Test shape: (3205, 26)\n"
     ]
    }
   ],
   "source": [
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_all, y_all, test_size=TEST_SIZE, random_state=RANDOM_STATE\n",
    ")\n",
    "print(\"Train shape:\", X_train.shape, \"Test shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "3e02cf29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models to run: ['LinearRegression', 'RandomForest', 'GradientBoosting', 'XGBoost', 'LightGBM', 'CatBoost']\n"
     ]
    }
   ],
   "source": [
    "# ---------- Models to train ----------\n",
    "models = {\n",
    "    \"LinearRegression\": {\"type\": \"sklearn\", \"est\": LinearRegression()},\n",
    "    \"RandomForest\": {\"type\": \"sklearn\", \"est\": RandomForestRegressor(n_estimators=150, max_depth=12, random_state=RANDOM_STATE, n_jobs=-1)},\n",
    "    \"GradientBoosting\": {\"type\": \"sklearn\", \"est\": GradientBoostingRegressor(n_estimators=150, learning_rate=0.05, max_depth=6, random_state=RANDOM_STATE)}\n",
    "}\n",
    "if xgb_available:\n",
    "    models[\"XGBoost\"] = {\"type\": \"booster\", \"est\": XGBRegressor(n_estimators=200, learning_rate=0.05, max_depth=6, subsample=0.8, colsample_bytree=0.8, objective=\"reg:squarederror\", random_state=RANDOM_STATE, n_jobs=-1, verbosity=0)}\n",
    "if lgb_available:\n",
    "    models[\"LightGBM\"] = {\"type\": \"booster\", \"est\": LGBMRegressor(n_estimators=200, learning_rate=0.05, max_depth=6, subsample=0.8, colsample_bytree=0.8, random_state=RANDOM_STATE, n_jobs=-1)}\n",
    "if cb_available:\n",
    "    models[\"CatBoost\"] = {\"type\": \"booster\", \"est\": CatBoostRegressor(iterations=200, learning_rate=0.05, depth=6, random_state=RANDOM_STATE, verbose=False)}\n",
    "\n",
    "print(\"Models to run:\", list(models.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "014e6f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training LinearRegression (type=sklearn) ...\n",
      "LinearRegression done — RMSE_price: 2625.62, MAE_price: 1826.49, time: 0.0s\n",
      "\n",
      "Training RandomForest (type=sklearn) ...\n",
      "RandomForest done — RMSE_price: 1723.00, MAE_price: 1170.91, time: 0.3s\n",
      "\n",
      "Training GradientBoosting (type=sklearn) ...\n",
      "GradientBoosting done — RMSE_price: 1707.48, MAE_price: 1216.72, time: 1.0s\n",
      "\n",
      "Training XGBoost (type=booster) ...\n",
      "XGBoost: fitted using method -> fallback_no_early_stopping\n",
      "XGBoost done — RMSE_price: 1689.42, MAE_price: 1191.51, time: 0.2s\n",
      "\n",
      "Training LightGBM (type=booster) ...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000182 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 343\n",
      "[LightGBM] [Info] Number of data points in the train set: 5981, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 8.991873\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\tvalid_0's l2: 0.0327995\n",
      "LightGBM: fitted using method -> lightgbm.callback.early_stopping\n",
      "LightGBM done — RMSE_price: 1740.74, MAE_price: 1234.31, time: 0.4s\n",
      "\n",
      "Training CatBoost (type=booster) ...\n",
      "CatBoost: fitted using method -> fit(early_stopping_rounds)\n",
      "CatBoost done — RMSE_price: 1876.62, MAE_price: 1350.06, time: 0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/campusx/lib/python3.12/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# ---------- TRAIN & EVAL ----------\n",
    "trained_pipelines = {}\n",
    "results = []\n",
    "\n",
    "for name, info in models.items():\n",
    "    model = info[\"est\"]\n",
    "    mtype = info[\"type\"]\n",
    "    print(f\"\\nTraining {name} (type={mtype}) ...\")\n",
    "    t0 = time.time()\n",
    "    try:\n",
    "        if mtype == \"sklearn\":\n",
    "            # For sklearn models fit on full outer training set\n",
    "            if preprocessor is not None:\n",
    "                pipe = Pipeline([(\"preprocessor\", preprocessor), (\"reg\", model)])\n",
    "                pipe.fit(X_train, y_train)\n",
    "                preds_log = pipe.predict(X_test)\n",
    "                final_pipeline = pipe  # ready to predict on raw rows\n",
    "            else:\n",
    "                # If no preprocessor, wrap scaler+lr only for LR\n",
    "                if name == \"LinearRegression\":\n",
    "                    lr_pipe = Pipeline([(\"scaler\", StandardScaler()), (\"lr\", model)])\n",
    "                    lr_pipe.fit(X_train, y_train)\n",
    "                    preds_log = lr_pipe.predict(X_test)\n",
    "                    final_pipeline = lr_pipe\n",
    "                else:\n",
    "                    model.fit(X_train, y_train)\n",
    "                    preds_log = model.predict(X_test)\n",
    "                    final_pipeline = Pipeline([(\"reg\", model)])\n",
    "\n",
    "        else:\n",
    "            # boosters: inner split for early stopping\n",
    "            X_tr, X_val, y_tr, y_val = train_test_split(X_train, y_train, test_size=0.20, random_state=RANDOM_STATE)\n",
    "            if preprocessor is not None:\n",
    "                # fit preprocessor on X_tr then transform\n",
    "                preprocessor.fit(X_tr)\n",
    "                X_tr_t = preprocessor.transform(X_tr)\n",
    "                X_val_t = preprocessor.transform(X_val)\n",
    "                X_test_t = preprocessor.transform(X_test)\n",
    "                # robust fit with fallback\n",
    "                fitted_booster, method = fit_booster_with_fallback(name, model, X_tr_t, y_tr, X_val_t, y_val)\n",
    "                print(f\"{name}: fitted using method -> {method}\")\n",
    "                preds_log = fitted_booster.predict(X_test_t)\n",
    "                final_pipeline = Pipeline([(\"preprocessor\", preprocessor), (\"reg\", fitted_booster)])\n",
    "            else:\n",
    "                X_tr_arr = X_tr.values if hasattr(X_tr, \"values\") else X_tr\n",
    "                X_val_arr = X_val.values if hasattr(X_val, \"values\") else X_val\n",
    "                X_test_arr = X_test.values if hasattr(X_test, \"values\") else X_test\n",
    "                fitted_booster, method = fit_booster_with_fallback(name, model, X_tr_arr, y_tr, X_val_arr, y_val)\n",
    "                print(f\"{name}: fitted using method -> {method}\")\n",
    "                preds_log = fitted_booster.predict(X_test_arr)\n",
    "                final_pipeline = Pipeline([(\"reg\", fitted_booster)])\n",
    "\n",
    "        # Evaluate\n",
    "        metrics = evaluate_predictions_log(y_test, preds_log)\n",
    "        metrics.update({\"Model\": name, \"time_sec\": time.time() - t0})\n",
    "        results.append(metrics)\n",
    "        trained_pipelines[name] = final_pipeline\n",
    "        print(f\"{name} done — RMSE_price: {metrics['rmse_price']:.2f}, MAE_price: {metrics['mae_price']:.2f}, time: {metrics['time_sec']:.1f}s\")\n",
    "\n",
    "    except Exception as e:\n",
    "        import traceback\n",
    "        print(f\"Error training {name}: {e}\")\n",
    "        traceback.print_exc()\n",
    "        results.append({\"Model\": name, \"rmse_log\": None, \"mae_log\": None, \"r2_log\": None, \"rmse_price\": None, \"mae_price\": None, \"r2_price\": str(e), \"time_sec\": None})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "922776fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = pd.DataFrame(results).sort_values(\"rmse_price\").reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "7df14f98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========= MODEL PERFORMANCE COMPARISON =========\n",
      "              Model   rmse_price    mae_price  r2_price  time_sec\n",
      "0           XGBoost  1689.419908  1191.505379  0.844077  0.191951\n",
      "1  GradientBoosting  1707.481507  1216.724772  0.840726  0.953026\n",
      "2      RandomForest  1722.998261  1170.914918  0.837818  0.257384\n",
      "3          LightGBM  1740.739690  1234.314434  0.834460  0.401225\n",
      "4          CatBoost  1876.616660  1350.058798  0.807609  0.149789\n",
      "5  LinearRegression  2625.618777  1826.491241  0.623385  0.007508\n",
      "\n",
      "========= BEST MODEL SELECTED =========\n",
      "Best Model: XGBoost\n",
      "RMSE (Price): 1689.4199\n",
      "MAE  (Price): 1191.5054\n",
      "R²   (Price): 0.8441\n",
      "Training Time: 0.19 seconds\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n========= MODEL PERFORMANCE COMPARISON =========\")\n",
    "print(res_df[[\"Model\", \"rmse_price\", \"mae_price\", \"r2_price\", \"time_sec\"]])\n",
    "\n",
    "# Pick best model based on RMSE on original price scale\n",
    "best_idx = res_df[\"rmse_price\"].idxmin()\n",
    "best_model_name = res_df.loc[best_idx, \"Model\"]\n",
    "best_model = trained_pipelines[best_model_name]\n",
    "\n",
    "print(\"\\n========= BEST MODEL SELECTED =========\")\n",
    "print(f\"Best Model: {best_model_name}\")\n",
    "print(f\"RMSE (Price): {res_df.loc[best_idx, 'rmse_price']:.4f}\")\n",
    "print(f\"MAE  (Price): {res_df.loc[best_idx, 'mae_price']:.4f}\")\n",
    "print(f\"R²   (Price): {res_df.loc[best_idx, 'r2_price']:.4f}\")\n",
    "print(f\"Training Time: {res_df.loc[best_idx, 'time_sec']:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "8ce9f3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"LinearRegression\": LinearRegression(),\n",
    "    \"RandomForest\": RandomForestRegressor(n_estimators=150, max_depth=12),\n",
    "    \"GradientBoosting\": GradientBoostingRegressor(n_estimators=150, learning_rate=0.05),\n",
    "    \"XGBoost\": XGBRegressor(n_estimators=150, learning_rate=0.05, max_depth=6)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "ffcc4269",
   "metadata": {},
   "outputs": [],
   "source": [
    "if xgb_available:\n",
    "    models[\"XGBoost\"] = XGBRegressor(\n",
    "        n_estimators=150,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=6,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        objective=\"reg:squarederror\",\n",
    "        verbosity=0\n",
    "    )\n",
    "\n",
    "if lgb_available:\n",
    "    models[\"LightGBM\"] = LGBMRegressor(\n",
    "        n_estimators=150,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=6,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8\n",
    "    )\n",
    "\n",
    "if cb_available:\n",
    "    models[\"CatBoost\"] = CatBoostRegressor(\n",
    "        iterations=150,\n",
    "        learning_rate=0.05,\n",
    "        depth=6,\n",
    "        verbose=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "0d0a5cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_states = [0, 21, 42, 73, 101, 123, 2024, 999]\n",
    "test_sizes = [0.30, 0.25, 0.20, 0.15]\n",
    "results = []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "d0d81988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000252 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 342\n",
      "[LightGBM] [Info] Number of data points in the train set: 7477, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 8.987314\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000250 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 342\n",
      "[LightGBM] [Info] Number of data points in the train set: 8011, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 8.986239\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000210 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 344\n",
      "[LightGBM] [Info] Number of data points in the train set: 8545, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 8.985513\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000396 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 347\n",
      "[LightGBM] [Info] Number of data points in the train set: 9079, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 8.985011\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000199 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 347\n",
      "[LightGBM] [Info] Number of data points in the train set: 7477, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 8.982208\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000199 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 348\n",
      "[LightGBM] [Info] Number of data points in the train set: 8011, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 8.983044\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000215 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 348\n",
      "[LightGBM] [Info] Number of data points in the train set: 8545, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 8.985347\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000221 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 346\n",
      "[LightGBM] [Info] Number of data points in the train set: 9079, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 8.985652\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000218 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 346\n",
      "[LightGBM] [Info] Number of data points in the train set: 7477, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 8.990258\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000207 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 346\n",
      "[LightGBM] [Info] Number of data points in the train set: 8011, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 8.988768\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000227 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 347\n",
      "[LightGBM] [Info] Number of data points in the train set: 8545, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 8.987063\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000236 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 347\n",
      "[LightGBM] [Info] Number of data points in the train set: 9079, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 8.986268\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000220 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 345\n",
      "[LightGBM] [Info] Number of data points in the train set: 7477, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 8.983757\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000213 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 344\n",
      "[LightGBM] [Info] Number of data points in the train set: 8011, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 8.986123\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000252 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 347\n",
      "[LightGBM] [Info] Number of data points in the train set: 8545, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 8.986085\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000218 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 345\n",
      "[LightGBM] [Info] Number of data points in the train set: 9079, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 8.985872\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000204 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 344\n",
      "[LightGBM] [Info] Number of data points in the train set: 7477, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 8.987165\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000216 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 347\n",
      "[LightGBM] [Info] Number of data points in the train set: 8011, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 8.988943\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000219 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 349\n",
      "[LightGBM] [Info] Number of data points in the train set: 8545, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 8.989273\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000237 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 347\n",
      "[LightGBM] [Info] Number of data points in the train set: 9079, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 8.988324\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000211 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 345\n",
      "[LightGBM] [Info] Number of data points in the train set: 7477, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 8.992160\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000255 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 344\n",
      "[LightGBM] [Info] Number of data points in the train set: 8011, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 8.990947\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000211 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 345\n",
      "[LightGBM] [Info] Number of data points in the train set: 8545, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 8.989145\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000222 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 346\n",
      "[LightGBM] [Info] Number of data points in the train set: 9079, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 8.987030\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000198 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 347\n",
      "[LightGBM] [Info] Number of data points in the train set: 7477, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 8.982825\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000206 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 346\n",
      "[LightGBM] [Info] Number of data points in the train set: 8011, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 8.983799\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000210 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 345\n",
      "[LightGBM] [Info] Number of data points in the train set: 8545, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 8.985004\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000211 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 348\n",
      "[LightGBM] [Info] Number of data points in the train set: 9079, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 8.986927\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000215 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 344\n",
      "[LightGBM] [Info] Number of data points in the train set: 7477, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 8.989140\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000258 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 346\n",
      "[LightGBM] [Info] Number of data points in the train set: 8011, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 8.987472\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000219 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 347\n",
      "[LightGBM] [Info] Number of data points in the train set: 8545, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 8.986208\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000225 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 346\n",
      "[LightGBM] [Info] Number of data points in the train set: 9079, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 8.985746\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>random_state</th>\n",
       "      <th>test_size</th>\n",
       "      <th>model</th>\n",
       "      <th>rmse</th>\n",
       "      <th>mae</th>\n",
       "      <th>r2</th>\n",
       "      <th>train_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.30</td>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>0.269583</td>\n",
       "      <td>0.203984</td>\n",
       "      <td>0.717741</td>\n",
       "      <td>0.028399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.30</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.185020</td>\n",
       "      <td>0.130581</td>\n",
       "      <td>0.867047</td>\n",
       "      <td>1.043341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.30</td>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>0.218017</td>\n",
       "      <td>0.169910</td>\n",
       "      <td>0.815395</td>\n",
       "      <td>0.469950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.30</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.178193</td>\n",
       "      <td>0.136160</td>\n",
       "      <td>0.876678</td>\n",
       "      <td>0.146930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.30</td>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.185125</td>\n",
       "      <td>0.142396</td>\n",
       "      <td>0.866895</td>\n",
       "      <td>0.342464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>999</td>\n",
       "      <td>0.15</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.180318</td>\n",
       "      <td>0.129122</td>\n",
       "      <td>0.870616</td>\n",
       "      <td>1.195189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>999</td>\n",
       "      <td>0.15</td>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>0.211269</td>\n",
       "      <td>0.164454</td>\n",
       "      <td>0.822387</td>\n",
       "      <td>0.580310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>999</td>\n",
       "      <td>0.15</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.173643</td>\n",
       "      <td>0.132906</td>\n",
       "      <td>0.880017</td>\n",
       "      <td>0.160141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>999</td>\n",
       "      <td>0.15</td>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.179896</td>\n",
       "      <td>0.138522</td>\n",
       "      <td>0.871221</td>\n",
       "      <td>0.294990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>999</td>\n",
       "      <td>0.15</td>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.196354</td>\n",
       "      <td>0.153435</td>\n",
       "      <td>0.846580</td>\n",
       "      <td>0.093639</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>192 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     random_state  test_size             model      rmse       mae        r2  \\\n",
       "0               0       0.30  LinearRegression  0.269583  0.203984  0.717741   \n",
       "1               0       0.30      RandomForest  0.185020  0.130581  0.867047   \n",
       "2               0       0.30  GradientBoosting  0.218017  0.169910  0.815395   \n",
       "3               0       0.30           XGBoost  0.178193  0.136160  0.876678   \n",
       "4               0       0.30          LightGBM  0.185125  0.142396  0.866895   \n",
       "..            ...        ...               ...       ...       ...       ...   \n",
       "187           999       0.15      RandomForest  0.180318  0.129122  0.870616   \n",
       "188           999       0.15  GradientBoosting  0.211269  0.164454  0.822387   \n",
       "189           999       0.15           XGBoost  0.173643  0.132906  0.880017   \n",
       "190           999       0.15          LightGBM  0.179896  0.138522  0.871221   \n",
       "191           999       0.15          CatBoost  0.196354  0.153435  0.846580   \n",
       "\n",
       "     train_time  \n",
       "0      0.028399  \n",
       "1      1.043341  \n",
       "2      0.469950  \n",
       "3      0.146930  \n",
       "4      0.342464  \n",
       "..          ...  \n",
       "187    1.195189  \n",
       "188    0.580310  \n",
       "189    0.160141  \n",
       "190    0.294990  \n",
       "191    0.093639  \n",
       "\n",
       "[192 rows x 7 columns]"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for rs in random_states:\n",
    "    for ts in test_sizes:\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X_all, y_all, test_size=ts, random_state=rs\n",
    "        )\n",
    "\n",
    "        for model_name, model in models.items():\n",
    "\n",
    "            t0 = time.time()\n",
    "            try:\n",
    "                model.fit(X_train, y_train)\n",
    "                preds = model.predict(X_test)\n",
    "            except Exception as e:\n",
    "                preds = np.full_like(y_test, y_test.mean())  # fallback dummy prediction\n",
    "\n",
    "            elapsed = time.time() - t0\n",
    "\n",
    "            metrics = {\n",
    "                \"random_state\": rs,\n",
    "                \"test_size\": ts,\n",
    "                \"model\": model_name,\n",
    "                \"rmse\": root_mean_squared_error(y_test, preds),\n",
    "                \"mae\": mean_absolute_error(y_test, preds),\n",
    "                \"r2\": r2_score(y_test, preds),\n",
    "                \"train_time\": elapsed\n",
    "            }\n",
    "\n",
    "            results.append(metrics)\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "759a1299",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.to_csv(\"dashboard_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "2f3b4e50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "random_state          42\n",
       "test_size           0.15\n",
       "model            XGBoost\n",
       "rmse            0.170429\n",
       "mae             0.129431\n",
       "r2              0.893197\n",
       "train_time      0.140429\n",
       "Name: 69, dtype: object"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_idx = df_results[\"rmse\"].idxmin()\n",
    "best_row = df_results.loc[best_idx]\n",
    "best_row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "5bed0b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best performance at random_state=42, test_size=0.15, model=XGBoost, RMSE=0.1704\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best performance at random_state={best_row.random_state}, \"\n",
    "      f\"test_size={best_row.test_size}, model={best_row.model}, \"\n",
    "      f\"RMSE={best_row.rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "9445756b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.to_json(\"dashboard_data.json\", orient=\"records\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "campusx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
